{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherry-tang-97/H-M_recommender/blob/main/H%26M_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O6NatEYJfUB",
        "outputId": "f802b2d9-1faf-49de-d690-b45692bc4ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 88 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 5.3 kB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 85.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 78.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 75.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "\n",
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "import re\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHHJmSeBJg0T",
        "outputId": "530dd0b1-3a74-4724-a20a-581fb1e407c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPGX_vvUtX6p"
      },
      "outputs": [],
      "source": [
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfhSaEx_CcIw"
      },
      "outputs": [],
      "source": [
        "#Read raw data\n",
        "samples = 200000\n",
        "transaction_df = pd.read_csv(\"/content/drive/MyDrive/hm_data/transactions_train.csv\", nrows= samples)\n",
        "articles_df = pd.read_csv(\"/content/drive/MyDrive/hm_data/articles.csv\")\n",
        "customers_df = pd.read_csv(\"/content/drive/MyDrive/hm_data/customers.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfD6QdnICuib"
      },
      "outputs": [],
      "source": [
        "#Merge information\n",
        "transaction_df = transaction_df.merge(customers_df, on = \"customer_id\", how = \"left\")\n",
        "\n",
        "transaction_df.article_id = transaction_df.article_id.astype(str)\n",
        "articles_df.article_id = articles_df.article_id.astype(str)\n",
        "\n",
        "transaction_df = transaction_df.merge(articles_df, on = \"article_id\", how = \"left\")\n",
        "\n",
        "volumn = transaction_df.article_id.value_counts().rename_axis('article_id').reset_index(name='vol')\n",
        "\n",
        "transaction_df = transaction_df.merge(volumn, on = \"article_id\", how = \"left\")\n",
        "articles_df = articles_df.merge(volumn, on = \"article_id\", how = \"left\")\n",
        "articles_df[\"vol\"] = articles_df[\"vol\"].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IBRMpz1JRuk"
      },
      "outputs": [],
      "source": [
        "#Choose desired cols\n",
        "transaction_df = transaction_df[['customer_id','article_id', 'age', 'product_type_name', 'graphical_appearance_name', 'colour_group_name', 'vol']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFZpfbNpJr0d"
      },
      "outputs": [],
      "source": [
        "#Turn transaction into dataset\n",
        "\n",
        "\n",
        "tensor_aid = tf.convert_to_tensor(transaction_df.article_id)\n",
        "tensor_ptn = tf.convert_to_tensor(transaction_df.product_type_name)\n",
        "tensor_gan = tf.convert_to_tensor(transaction_df.graphical_appearance_name)\n",
        "tensor_cgn = tf.convert_to_tensor(transaction_df.colour_group_name)\n",
        "tensor_cid = tf.convert_to_tensor(transaction_df.customer_id)\n",
        "tensor_age = tf.convert_to_tensor(transaction_df.age)\n",
        "tensor_vol = tf.convert_to_tensor(transaction_df.vol)\n",
        "\n",
        "dict_transaction = {\"article_id\": tensor_aid, \n",
        "                 \"product_type_name\": tensor_ptn, \n",
        "                 \"graphical_appearance_name\" : tensor_gan, \n",
        "                 \"colour_group_name\" : tensor_cgn, \n",
        "                 \"customer_id\": tensor_cid, \n",
        "                 \"age\": tensor_age, \n",
        "                 \"vol\": tensor_vol\n",
        "}\n",
        "\n",
        "\n",
        "transaction = tf.data.Dataset.from_tensor_slices(dict_transaction)\n",
        "\n",
        "\n",
        "del tensor_aid, tensor_ptn, tensor_gan, tensor_cgn, tensor_cid, tensor_age, tensor_vol, dict_transaction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xQANMG1gnu5"
      },
      "outputs": [],
      "source": [
        "#Turn article & customer into dataset\n",
        "\n",
        "tensor_aid = tf.convert_to_tensor(articles_df.article_id)\n",
        "tensor_ptn = tf.convert_to_tensor(articles_df.product_type_name)\n",
        "tensor_gan = tf.convert_to_tensor(articles_df.graphical_appearance_name)\n",
        "tensor_cgn = tf.convert_to_tensor(articles_df.colour_group_name)\n",
        "tensor_vol = tf.convert_to_tensor(articles_df.vol)\n",
        "\n",
        "dict_articles = {\"article_id\": tensor_aid, \n",
        "                 \"product_type_name\": tensor_ptn, \n",
        "                 \"graphical_appearance_name\" : tensor_gan, \n",
        "                 \"colour_group_name\" : tensor_cgn, \n",
        "                 \"vol\": tensor_vol\n",
        "}\n",
        "\n",
        "articles = tf.data.Dataset.from_tensor_slices(dict_articles)\n",
        "\n",
        "\n",
        "del tensor_aid, tensor_ptn, tensor_gan, tensor_cgn, tensor_vol, dict_articles\n",
        "\n",
        "\n",
        "tensor_cid = tf.convert_to_tensor(customers_df.customer_id)\n",
        "tensor_age = tf.convert_to_tensor(customers_df.age)\n",
        "\n",
        "dict_customers = {\"customer_id\": tensor_cid, \n",
        "                 \"age\": tensor_age\n",
        "}\n",
        "\n",
        "customers = tf.data.Dataset.from_tensor_slices(dict_customers)\n",
        "\n",
        "del tensor_cid, tensor_age, dict_customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBt0xhX3J4Ng"
      },
      "outputs": [],
      "source": [
        "#Train/valid/test split\n",
        "from tensorflow.python.ops.gen_dataset_ops import shuffle_and_repeat_dataset\n",
        "tf.random.set_seed(9586)\n",
        "shuffled = transaction.shuffle(samples, seed=9586, reshuffle_each_iteration=False)\n",
        "\n",
        "train_num = round(samples*0.8*0.8)\n",
        "valid_num = round(samples*0.8*0.2)\n",
        "test_num = round(samples*0.2)\n",
        "\n",
        "train = shuffled.take(train_num)\n",
        "valid = shuffled.skip(train_num).take(valid_num)\n",
        "test = shuffled.skip(train_num + valid_num).take(test_num)\n",
        "\n",
        "del shuffled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioFIAyubmmWK"
      },
      "outputs": [],
      "source": [
        "#Unique values\n",
        "uaid = articles.batch(10000).map(lambda x: x[\"article_id\"])\n",
        "uptn = articles.batch(10000).map(lambda x: x[\"product_type_name\"])\n",
        "ugan = articles.batch(10000).map(lambda x: x[\"graphical_appearance_name\"])\n",
        "ucgn = articles.batch(10000).map(lambda x: x[\"colour_group_name\"])\n",
        "\n",
        "ucid = customers.batch(50000).map(lambda x: x[\"customer_id\"])\n",
        "\n",
        "\n",
        "uaid = np.unique(np.concatenate(list(uaid)))\n",
        "uptn = np.unique(np.concatenate(list(uptn)))\n",
        "ugan = np.unique(np.concatenate(list(ugan)))\n",
        "ucgn = np.unique(np.concatenate(list(ucgn)))\n",
        "ucid = np.unique(np.concatenate(list(ucid)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c0guGVjJ8TV"
      },
      "outputs": [],
      "source": [
        "#Base model\n",
        "embedding_dimension = 32\n",
        "customer_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=ucid, mask_token=None),\n",
        "  # We add an additional embedding to account for unknown tokens.\n",
        "  tf.keras.layers.Embedding(len(ucid) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "article_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=uaid, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(uaid) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "metrics = tfrs.metrics.FactorizedTopK(\n",
        "  candidates=articles.batch(10000).map(lambda x: x[\"article_id\"]).map(article_model)\n",
        ")\n",
        "task = tfrs.tasks.Retrieval(\n",
        "  metrics=metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzOUjtE4KCIk"
      },
      "outputs": [],
      "source": [
        "#Base model\n",
        "class HM_Model(tfrs.Model):\n",
        "  \n",
        "  def __init__(self, customer_model, article_model):\n",
        "    super().__init__()\n",
        "    self.article_model: tf.keras.Model = article_model\n",
        "    self.customer_model: tf.keras.Model = customer_model\n",
        "    self.task: tf.keras.layers.Layer = task\n",
        "\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    customer_embeddings = self.customer_model(features[\"customer_id\"])\n",
        "    # And pick out the movie features and pass them into the movie model,\n",
        "    # getting embeddings back.\n",
        "    positive_article_embeddings = self.article_model(features[\"article_id\"])\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(customer_embeddings, positive_article_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwmIgwX4KHwa"
      },
      "outputs": [],
      "source": [
        "#Prepare data for training\n",
        "model = HM_Model(customer_model, article_model)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
        "\n",
        "train_batch = round(train_num/5)\n",
        "valid_batch = round(valid_num/5)\n",
        "test_batch = round(test_num/5)\n",
        "\n",
        "cached_train = train.shuffle(train_num).batch(train_batch).cache()\n",
        "cached_valid = valid.batch(valid_batch).cache()\n",
        "cached_test = test.batch(test_batch).cache()\n",
        "\n",
        "cached_train = cached_train.prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNN-ziCTKOt1",
        "outputId": "e6ada404-e18a-4f79-8255-b0e47505202b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 28s 6s/step - factorized_top_k/top_1_categorical_accuracy: 0.2141 - factorized_top_k/top_5_categorical_accuracy: 0.7799 - factorized_top_k/top_10_categorical_accuracy: 0.9131 - factorized_top_k/top_50_categorical_accuracy: 0.9908 - factorized_top_k/top_100_categorical_accuracy: 0.9961 - loss: 94389.0299 - regularization_loss: 0.0000e+00 - total_loss: 94389.0299 - val_factorized_top_k/top_1_categorical_accuracy: 0.0310 - val_factorized_top_k/top_5_categorical_accuracy: 0.1086 - val_factorized_top_k/top_10_categorical_accuracy: 0.1330 - val_factorized_top_k/top_50_categorical_accuracy: 0.1637 - val_factorized_top_k/top_100_categorical_accuracy: 0.1787 - val_loss: 85843.5625 - val_regularization_loss: 0.0000e+00 - val_total_loss: 85843.5625\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - ETA: 0s - factorized_top_k/top_1_categorical_accuracy: 0.2256 - factorized_top_k/top_5_categorical_accuracy: 0.8074 - factorized_top_k/top_10_categorical_accuracy: 0.9364 - factorized_top_k/top_50_categorical_accuracy: 0.9941 - factorized_top_k/top_100_categorical_accuracy: 0.9973 - loss: 80843.9516 - regularization_loss: 0.0000e+00 - total_loss: 80843.9516"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f11192910354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Fit base model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1454\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1457\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Fit base model\n",
        "start = time.time()\n",
        "model.fit(cached_train, epochs = 10, validation_data = cached_valid)\n",
        "end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyyXwbzNEQJ2"
      },
      "outputs": [],
      "source": [
        "#Base model run time\n",
        "print(end-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qdEWeP8K6E-",
        "outputId": "e338d97c-48af-4c28-adda-52d38848eb52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0303 - factorized_top_k/top_5_categorical_accuracy: 0.0984 - factorized_top_k/top_10_categorical_accuracy: 0.1188 - factorized_top_k/top_50_categorical_accuracy: 0.1593 - factorized_top_k/top_100_categorical_accuracy: 0.1805 - loss: 74826.7591 - regularization_loss: 0.0000e+00 - total_loss: 74826.7591\n",
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f8e40a9d4d0> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7f8e40a9d4d0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
            "Match 0:\n",
            "(lambda x: x['article_id'])\n",
            "\n",
            "Match 1:\n",
            "(lambda x: x['article_id'])\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7f8e40a9d4d0> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7f8e40a9d4d0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
            "Match 0:\n",
            "(lambda x: x['article_id'])\n",
            "\n",
            "Match 1:\n",
            "(lambda x: x['article_id'])\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f8e40a8c950> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7f8e40a8c950>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
            "Match 0:\n",
            "(lambda x: x['article_id'])\n",
            "\n",
            "Match 1:\n",
            "(lambda x: x['article_id'])\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7f8e40a8c950> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7f8e40a8c950>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
            "Match 0:\n",
            "(lambda x: x['article_id'])\n",
            "\n",
            "Match 1:\n",
            "(lambda x: x['article_id'])\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7f8e40ea3d10>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Evaluate base model\n",
        "model.evaluate(cached_test, return_dict=True)\n",
        "# Create a model that takes in raw query features, and\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.customer_model)\n",
        "# recommends movies out of the entire movies dataset.\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((articles.batch(10000).map(lambda x: x[\"article_id\"]), articles.batch(10000).map(lambda x: x[\"article_id\"]).map(model.article_model)))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOW-hB9sYzeB"
      },
      "outputs": [],
      "source": [
        "#Complex model 1: included article & customer features\n",
        "\n",
        "#Preprocess article features\n",
        "\n",
        "aid_emb = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=uaid, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(uaid) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "ptn_emb = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=uptn, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(uptn) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "gan_emb = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=ugan, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(ugan) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "cgn_emb = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=ucgn, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(ucgn) + 1, embedding_dimension)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYXmOpL2cQ2T"
      },
      "outputs": [],
      "source": [
        "#Article model\n",
        "class articleModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.aid_emb = aid_emb\n",
        "    self.ptn_emb = ptn_emb\n",
        "    self.gan_emb = gan_emb\n",
        "    self.cgn_emb = cgn_emb\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    return tf.concat([\n",
        "        self.aid_emb(inputs[\"article_id\"]),\n",
        "        self.ptn_emb(inputs[\"product_type_name\"]),\n",
        "        self.gan_emb(inputs[\"graphical_appearance_name\"]),\n",
        "        self.cgn_emb(inputs[\"colour_group_name\"])], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGu52Z3Kyyxx"
      },
      "outputs": [],
      "source": [
        "#Preprocess customer features\n",
        "\n",
        "cid_emb = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=ucid, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(ucid) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "#age_emb = tf.keras.layers.Normalization(\n",
        "        #axis=None\n",
        "    #)\n",
        "\n",
        "#Customer model\n",
        "class customerModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.cid_emb = cid_emb\n",
        "    #self.age_emb = age_emb\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    return tf.concat([\n",
        "        self.cid_emb(inputs[\"customer_id\"]),\n",
        "        #tf.reshape(self.age_emb(inputs[\"age\"]), (-1, 1))\n",
        "    ], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzaK6FSI4w67"
      },
      "outputs": [],
      "source": [
        "#Complex model 1\n",
        "class HM_Model_1(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.query_model = tf.keras.Sequential([\n",
        "      customerModel(),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "\n",
        "    self.candidate_model = tf.keras.Sequential([\n",
        "      articleModel(),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "                        \n",
        "    self.task = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=articles.batch(10000).map(self.candidate_model),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    # We only pass the user id and timestamp features into the query model. This\n",
        "    # is to ensure that the training inputs would have the same keys as the\n",
        "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
        "    # error when loading the query model after saving it.\n",
        "    query_embeddings = self.query_model({\n",
        "        \"customer_id\": features[\"customer_id\"],\n",
        "        #\"age\": features[\"age\"],\n",
        "    })\n",
        "    candidate_embeddings = self.candidate_model({\n",
        "        \"article_id\": features[\"article_id\"],\n",
        "        \"product_type_name\": features[\"product_type_name\"],\n",
        "        \"graphical_appearance_name\": features[\"graphical_appearance_name\"],\n",
        "        \"colour_group_name\": features[\"colour_group_name\"],\n",
        "    })\n",
        "\n",
        "    return self.task(query_embeddings, candidate_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfQ0yjffMPKk",
        "outputId": "7f1c0895-8392-4e74-eb6e-7057f12340fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'article_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'args_3:0' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'args_2:0' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>, 'vol': <tf.Tensor 'args_4:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n"
          ]
        }
      ],
      "source": [
        "#Prepare data for training\n",
        "model = HM_Model_1()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
        "\n",
        "cached_train = train.shuffle(train_num).batch(train_batch).cache()\n",
        "cached_valid = valid.batch(valid_batch).cache()\n",
        "cached_test = test.batch(test_batch).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzcldZ87EifO",
        "outputId": "517140e3-7229-414f-c584-59ae035ef3cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "5/5 [==============================] - ETA: 0s - factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 9.5313e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0019 - factorized_top_k/top_50_categorical_accuracy: 0.0049 - factorized_top_k/top_100_categorical_accuracy: 0.0072 - loss: 260288.8062 - regularization_loss: 0.0000e+00 - total_loss: 260288.8062    WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "5/5 [==============================] - 28s 6s/step - factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 9.5313e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0019 - factorized_top_k/top_50_categorical_accuracy: 0.0049 - factorized_top_k/top_100_categorical_accuracy: 0.0072 - loss: 260170.4323 - regularization_loss: 0.0000e+00 - total_loss: 260170.4323 - val_factorized_top_k/top_1_categorical_accuracy: 0.0011 - val_factorized_top_k/top_5_categorical_accuracy: 0.0041 - val_factorized_top_k/top_10_categorical_accuracy: 0.0062 - val_factorized_top_k/top_50_categorical_accuracy: 0.0132 - val_factorized_top_k/top_100_categorical_accuracy: 0.0194 - val_loss: 56048.3438 - val_regularization_loss: 0.0000e+00 - val_total_loss: 56048.3438\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 25s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0021 - factorized_top_k/top_5_categorical_accuracy: 0.0084 - factorized_top_k/top_10_categorical_accuracy: 0.0122 - factorized_top_k/top_50_categorical_accuracy: 0.0273 - factorized_top_k/top_100_categorical_accuracy: 0.0378 - loss: 249967.8099 - regularization_loss: 0.0000e+00 - total_loss: 249967.8099 - val_factorized_top_k/top_1_categorical_accuracy: 0.0040 - val_factorized_top_k/top_5_categorical_accuracy: 0.0127 - val_factorized_top_k/top_10_categorical_accuracy: 0.0193 - val_factorized_top_k/top_50_categorical_accuracy: 0.0450 - val_factorized_top_k/top_100_categorical_accuracy: 0.0635 - val_loss: 54857.7656 - val_regularization_loss: 0.0000e+00 - val_total_loss: 54857.7656\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 25s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0098 - factorized_top_k/top_5_categorical_accuracy: 0.0392 - factorized_top_k/top_10_categorical_accuracy: 0.0591 - factorized_top_k/top_50_categorical_accuracy: 0.1279 - factorized_top_k/top_100_categorical_accuracy: 0.1700 - loss: 226643.8620 - regularization_loss: 0.0000e+00 - total_loss: 226643.8620 - val_factorized_top_k/top_1_categorical_accuracy: 0.0060 - val_factorized_top_k/top_5_categorical_accuracy: 0.0247 - val_factorized_top_k/top_10_categorical_accuracy: 0.0353 - val_factorized_top_k/top_50_categorical_accuracy: 0.0773 - val_factorized_top_k/top_100_categorical_accuracy: 0.1037 - val_loss: 56303.6016 - val_regularization_loss: 0.0000e+00 - val_total_loss: 56303.6016\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 25s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0340 - factorized_top_k/top_5_categorical_accuracy: 0.1213 - factorized_top_k/top_10_categorical_accuracy: 0.1695 - factorized_top_k/top_50_categorical_accuracy: 0.3080 - factorized_top_k/top_100_categorical_accuracy: 0.3815 - loss: 199401.2656 - regularization_loss: 0.0000e+00 - total_loss: 199401.2656 - val_factorized_top_k/top_1_categorical_accuracy: 0.0122 - val_factorized_top_k/top_5_categorical_accuracy: 0.0370 - val_factorized_top_k/top_10_categorical_accuracy: 0.0500 - val_factorized_top_k/top_50_categorical_accuracy: 0.0954 - val_factorized_top_k/top_100_categorical_accuracy: 0.1224 - val_loss: 60636.2969 - val_regularization_loss: 0.0000e+00 - val_total_loss: 60636.2969\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 24s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0717 - factorized_top_k/top_5_categorical_accuracy: 0.2118 - factorized_top_k/top_10_categorical_accuracy: 0.2706 - factorized_top_k/top_50_categorical_accuracy: 0.4315 - factorized_top_k/top_100_categorical_accuracy: 0.5110 - loss: 176919.9635 - regularization_loss: 0.0000e+00 - total_loss: 176919.9635 - val_factorized_top_k/top_1_categorical_accuracy: 0.0165 - val_factorized_top_k/top_5_categorical_accuracy: 0.0471 - val_factorized_top_k/top_10_categorical_accuracy: 0.0609 - val_factorized_top_k/top_50_categorical_accuracy: 0.1066 - val_factorized_top_k/top_100_categorical_accuracy: 0.1371 - val_loss: 64025.9883 - val_regularization_loss: 0.0000e+00 - val_total_loss: 64025.9883\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 25s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.1069 - factorized_top_k/top_5_categorical_accuracy: 0.2815 - factorized_top_k/top_10_categorical_accuracy: 0.3456 - factorized_top_k/top_50_categorical_accuracy: 0.5195 - factorized_top_k/top_100_categorical_accuracy: 0.6026 - loss: 159144.1901 - regularization_loss: 0.0000e+00 - total_loss: 159144.1901 - val_factorized_top_k/top_1_categorical_accuracy: 0.0203 - val_factorized_top_k/top_5_categorical_accuracy: 0.0529 - val_factorized_top_k/top_10_categorical_accuracy: 0.0676 - val_factorized_top_k/top_50_categorical_accuracy: 0.1120 - val_factorized_top_k/top_100_categorical_accuracy: 0.1436 - val_loss: 66879.3906 - val_regularization_loss: 0.0000e+00 - val_total_loss: 66879.3906\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 24s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.1406 - factorized_top_k/top_5_categorical_accuracy: 0.3424 - factorized_top_k/top_10_categorical_accuracy: 0.4179 - factorized_top_k/top_50_categorical_accuracy: 0.5994 - factorized_top_k/top_100_categorical_accuracy: 0.6795 - loss: 144769.4974 - regularization_loss: 0.0000e+00 - total_loss: 144769.4974 - val_factorized_top_k/top_1_categorical_accuracy: 0.0219 - val_factorized_top_k/top_5_categorical_accuracy: 0.0591 - val_factorized_top_k/top_10_categorical_accuracy: 0.0741 - val_factorized_top_k/top_50_categorical_accuracy: 0.1238 - val_factorized_top_k/top_100_categorical_accuracy: 0.1539 - val_loss: 69959.8672 - val_regularization_loss: 0.0000e+00 - val_total_loss: 69959.8672\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 24s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.1548 - factorized_top_k/top_5_categorical_accuracy: 0.3909 - factorized_top_k/top_10_categorical_accuracy: 0.4741 - factorized_top_k/top_50_categorical_accuracy: 0.6590 - factorized_top_k/top_100_categorical_accuracy: 0.7326 - loss: 135403.6198 - regularization_loss: 0.0000e+00 - total_loss: 135403.6198 - val_factorized_top_k/top_1_categorical_accuracy: 0.0250 - val_factorized_top_k/top_5_categorical_accuracy: 0.0655 - val_factorized_top_k/top_10_categorical_accuracy: 0.0820 - val_factorized_top_k/top_50_categorical_accuracy: 0.1309 - val_factorized_top_k/top_100_categorical_accuracy: 0.1601 - val_loss: 71993.0547 - val_regularization_loss: 0.0000e+00 - val_total_loss: 71993.0547\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 25s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.1659 - factorized_top_k/top_5_categorical_accuracy: 0.4315 - factorized_top_k/top_10_categorical_accuracy: 0.5199 - factorized_top_k/top_50_categorical_accuracy: 0.7032 - factorized_top_k/top_100_categorical_accuracy: 0.7700 - loss: 128639.1094 - regularization_loss: 0.0000e+00 - total_loss: 128639.1094 - val_factorized_top_k/top_1_categorical_accuracy: 0.0234 - val_factorized_top_k/top_5_categorical_accuracy: 0.0697 - val_factorized_top_k/top_10_categorical_accuracy: 0.0873 - val_factorized_top_k/top_50_categorical_accuracy: 0.1391 - val_factorized_top_k/top_100_categorical_accuracy: 0.1689 - val_loss: 73715.7188 - val_regularization_loss: 0.0000e+00 - val_total_loss: 73715.7188\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 24s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.1715 - factorized_top_k/top_5_categorical_accuracy: 0.4667 - factorized_top_k/top_10_categorical_accuracy: 0.5606 - factorized_top_k/top_50_categorical_accuracy: 0.7400 - factorized_top_k/top_100_categorical_accuracy: 0.8015 - loss: 123174.4727 - regularization_loss: 0.0000e+00 - total_loss: 123174.4727 - val_factorized_top_k/top_1_categorical_accuracy: 0.0261 - val_factorized_top_k/top_5_categorical_accuracy: 0.0747 - val_factorized_top_k/top_10_categorical_accuracy: 0.0920 - val_factorized_top_k/top_50_categorical_accuracy: 0.1414 - val_factorized_top_k/top_100_categorical_accuracy: 0.1707 - val_loss: 75380.8203 - val_regularization_loss: 0.0000e+00 - val_total_loss: 75380.8203\n"
          ]
        }
      ],
      "source": [
        "#Fit complex model 1\n",
        "start = time.time()\n",
        "model.fit(cached_train, epochs = 10, validation_data = cached_valid)\n",
        "end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjuSjMfbhBgB",
        "outputId": "d302912b-3a23-4ed0-a088-3bf55a95e742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "249.23756647109985\n"
          ]
        }
      ],
      "source": [
        "#Complex model 1 run time\n",
        "print(end-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULdnczBMG17J",
        "outputId": "4fbc1fa0-27e4-43bc-b391-fee5c838ebc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0254 - factorized_top_k/top_5_categorical_accuracy: 0.0723 - factorized_top_k/top_10_categorical_accuracy: 0.0891 - factorized_top_k/top_50_categorical_accuracy: 0.1404 - factorized_top_k/top_100_categorical_accuracy: 0.1698 - loss: 95770.1302 - regularization_loss: 0.0000e+00 - total_loss: 95770.1302\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'factorized_top_k/top_100_categorical_accuracy': 0.1698250025510788,\n",
              " 'factorized_top_k/top_10_categorical_accuracy': 0.08905000239610672,\n",
              " 'factorized_top_k/top_1_categorical_accuracy': 0.0253749992698431,\n",
              " 'factorized_top_k/top_50_categorical_accuracy': 0.1404000073671341,\n",
              " 'factorized_top_k/top_5_categorical_accuracy': 0.07227499783039093,\n",
              " 'loss': 95605.5234375,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 95605.5234375}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Evaluate complex model 1\n",
        "model.evaluate(cached_test, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGjIZ6_O5vSj"
      },
      "outputs": [],
      "source": [
        "#Complex model 2: included popularity feature\n",
        "\n",
        "#Preprocess article features\n",
        "aid_emb = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=uaid, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(uaid) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "\n",
        "vol_emb = tf.keras.layers.Normalization(\n",
        "        axis=None\n",
        "    )\n",
        "\n",
        "\n",
        "#Article model\n",
        "class articleModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.aid_emb = aid_emb\n",
        "    self.vol_emb = vol_emb\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    return tf.concat([\n",
        "        self.aid_emb(inputs[\"article_id\"]),\n",
        "        tf.reshape(self.vol_emb(inputs[\"vol\"]), (-1, 1))\n",
        "    ], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udEptkkwpveg"
      },
      "outputs": [],
      "source": [
        "#Preprocess customer feature\n",
        "cid_emb = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=ucid, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(ucid) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "#Customer model\n",
        "class customerModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.cid_emb = cid_emb\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    return tf.concat([\n",
        "        self.cid_emb(inputs[\"customer_id\"]),\n",
        "    ], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvPIVdeLqmrX"
      },
      "outputs": [],
      "source": [
        "#Complex model 2\n",
        "class HM_Model_2(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.query_model = tf.keras.Sequential([\n",
        "      customerModel(),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "\n",
        "    self.candidate_model = tf.keras.Sequential([\n",
        "      articleModel(),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "                        \n",
        "    self.task = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=articles.batch(10000).map(self.candidate_model),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    # We only pass the user id and timestamp features into the query model. This\n",
        "    # is to ensure that the training inputs would have the same keys as the\n",
        "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
        "    # error when loading the query model after saving it.\n",
        "    query_embeddings = self.query_model({\n",
        "        \"customer_id\": features[\"customer_id\"]\n",
        "    })\n",
        "    candidate_embeddings = self.candidate_model({\n",
        "        \"article_id\": features[\"article_id\"],\n",
        "        \"vol\": features[\"vol\"]\n",
        "    })\n",
        "\n",
        "    return self.task(query_embeddings, candidate_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czmsViaVeke8",
        "outputId": "fad076c8-da18-4d9f-c8b7-8fdccb81cce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'article_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'args_3:0' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'args_2:0' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>, 'vol': <tf.Tensor 'args_4:0' shape=(None,) dtype=float64>}. Consider rewriting this model with the Functional API.\n"
          ]
        }
      ],
      "source": [
        "#Prepare data for training\n",
        "model = HM_Model_2()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
        "\n",
        "cached_train = train.shuffle(train_num).batch(train_batch).cache()\n",
        "cached_valid = valid.batch(valid_batch).cache()\n",
        "cached_test = test.batch(test_batch).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdbDOPR7etoD",
        "outputId": "8091cc2b-909c-4565-cee8-c0e87dd2842c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'vol': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'vol': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
            "5/5 [==============================] - ETA: 0s - factorized_top_k/top_1_categorical_accuracy: 9.2969e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0054 - factorized_top_k/top_10_categorical_accuracy: 0.0076 - factorized_top_k/top_50_categorical_accuracy: 0.0198 - factorized_top_k/top_100_categorical_accuracy: 0.0302 - loss: 1535958.0250 - regularization_loss: 0.0000e+00 - total_loss: 1535958.0250WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'vol': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
            "5/5 [==============================] - 28s 6s/step - factorized_top_k/top_1_categorical_accuracy: 9.2969e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0054 - factorized_top_k/top_10_categorical_accuracy: 0.0076 - factorized_top_k/top_50_categorical_accuracy: 0.0198 - factorized_top_k/top_100_categorical_accuracy: 0.0302 - loss: 1387458.7917 - regularization_loss: 0.0000e+00 - total_loss: 1387458.7917 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 9.3750e-05 - val_factorized_top_k/top_50_categorical_accuracy: 5.9375e-04 - val_factorized_top_k/top_100_categorical_accuracy: 0.0013 - val_loss: 118986.6641 - val_regularization_loss: 0.0000e+00 - val_total_loss: 118986.6641\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 24s 5s/step - factorized_top_k/top_1_categorical_accuracy: 3.2812e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0022 - factorized_top_k/top_10_categorical_accuracy: 0.0038 - factorized_top_k/top_50_categorical_accuracy: 0.0140 - factorized_top_k/top_100_categorical_accuracy: 0.0244 - loss: 355727.8958 - regularization_loss: 0.0000e+00 - total_loss: 355727.8958 - val_factorized_top_k/top_1_categorical_accuracy: 9.3750e-05 - val_factorized_top_k/top_5_categorical_accuracy: 5.6250e-04 - val_factorized_top_k/top_10_categorical_accuracy: 8.7500e-04 - val_factorized_top_k/top_50_categorical_accuracy: 0.0028 - val_factorized_top_k/top_100_categorical_accuracy: 0.0044 - val_loss: 72611.5859 - val_regularization_loss: 0.0000e+00 - val_total_loss: 72611.5859\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 24s 5s/step - factorized_top_k/top_1_categorical_accuracy: 8.8281e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0057 - factorized_top_k/top_10_categorical_accuracy: 0.0083 - factorized_top_k/top_50_categorical_accuracy: 0.0218 - factorized_top_k/top_100_categorical_accuracy: 0.0328 - loss: 609255.6875 - regularization_loss: 0.0000e+00 - total_loss: 609255.6875 - val_factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0021 - val_factorized_top_k/top_10_categorical_accuracy: 0.0031 - val_factorized_top_k/top_50_categorical_accuracy: 0.0090 - val_factorized_top_k/top_100_categorical_accuracy: 0.0151 - val_loss: 141684.7656 - val_regularization_loss: 0.0000e+00 - val_total_loss: 141684.7656\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 25s 5s/step - factorized_top_k/top_1_categorical_accuracy: 5.1562e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0028 - factorized_top_k/top_10_categorical_accuracy: 0.0044 - factorized_top_k/top_50_categorical_accuracy: 0.0129 - factorized_top_k/top_100_categorical_accuracy: 0.0211 - loss: 440943.0156 - regularization_loss: 0.0000e+00 - total_loss: 440943.0156 - val_factorized_top_k/top_1_categorical_accuracy: 0.0011 - val_factorized_top_k/top_5_categorical_accuracy: 0.0049 - val_factorized_top_k/top_10_categorical_accuracy: 0.0070 - val_factorized_top_k/top_50_categorical_accuracy: 0.0193 - val_factorized_top_k/top_100_categorical_accuracy: 0.0333 - val_loss: 91581.2422 - val_regularization_loss: 0.0000e+00 - val_total_loss: 91581.2422\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 24s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0074 - factorized_top_k/top_10_categorical_accuracy: 0.0108 - factorized_top_k/top_50_categorical_accuracy: 0.0316 - factorized_top_k/top_100_categorical_accuracy: 0.0515 - loss: 314070.4010 - regularization_loss: 0.0000e+00 - total_loss: 314070.4010 - val_factorized_top_k/top_1_categorical_accuracy: 7.1875e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0057 - val_factorized_top_k/top_10_categorical_accuracy: 0.0077 - val_factorized_top_k/top_50_categorical_accuracy: 0.0211 - val_factorized_top_k/top_100_categorical_accuracy: 0.0344 - val_loss: 77763.6250 - val_regularization_loss: 0.0000e+00 - val_total_loss: 77763.6250\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 26s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0088 - factorized_top_k/top_10_categorical_accuracy: 0.0126 - factorized_top_k/top_50_categorical_accuracy: 0.0341 - factorized_top_k/top_100_categorical_accuracy: 0.0546 - loss: 288093.8802 - regularization_loss: 0.0000e+00 - total_loss: 288093.8802 - val_factorized_top_k/top_1_categorical_accuracy: 0.0013 - val_factorized_top_k/top_5_categorical_accuracy: 0.0075 - val_factorized_top_k/top_10_categorical_accuracy: 0.0109 - val_factorized_top_k/top_50_categorical_accuracy: 0.0370 - val_factorized_top_k/top_100_categorical_accuracy: 0.0613 - val_loss: 75300.9297 - val_regularization_loss: 0.0000e+00 - val_total_loss: 75300.9297\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 24s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0026 - factorized_top_k/top_5_categorical_accuracy: 0.0134 - factorized_top_k/top_10_categorical_accuracy: 0.0194 - factorized_top_k/top_50_categorical_accuracy: 0.0558 - factorized_top_k/top_100_categorical_accuracy: 0.0868 - loss: 272699.5469 - regularization_loss: 0.0000e+00 - total_loss: 272699.5469 - val_factorized_top_k/top_1_categorical_accuracy: 0.0012 - val_factorized_top_k/top_5_categorical_accuracy: 0.0028 - val_factorized_top_k/top_10_categorical_accuracy: 0.0042 - val_factorized_top_k/top_50_categorical_accuracy: 0.0096 - val_factorized_top_k/top_100_categorical_accuracy: 0.0151 - val_loss: 73198.4219 - val_regularization_loss: 0.0000e+00 - val_total_loss: 73198.4219\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 23s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0029 - factorized_top_k/top_5_categorical_accuracy: 0.0137 - factorized_top_k/top_10_categorical_accuracy: 0.0204 - factorized_top_k/top_50_categorical_accuracy: 0.0564 - factorized_top_k/top_100_categorical_accuracy: 0.0864 - loss: 263516.6354 - regularization_loss: 0.0000e+00 - total_loss: 263516.6354 - val_factorized_top_k/top_1_categorical_accuracy: 0.0016 - val_factorized_top_k/top_5_categorical_accuracy: 0.0111 - val_factorized_top_k/top_10_categorical_accuracy: 0.0157 - val_factorized_top_k/top_50_categorical_accuracy: 0.0435 - val_factorized_top_k/top_100_categorical_accuracy: 0.0695 - val_loss: 70745.1250 - val_regularization_loss: 0.0000e+00 - val_total_loss: 70745.1250\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 25s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0040 - factorized_top_k/top_5_categorical_accuracy: 0.0194 - factorized_top_k/top_10_categorical_accuracy: 0.0290 - factorized_top_k/top_50_categorical_accuracy: 0.0769 - factorized_top_k/top_100_categorical_accuracy: 0.1145 - loss: 256297.8177 - regularization_loss: 0.0000e+00 - total_loss: 256297.8177 - val_factorized_top_k/top_1_categorical_accuracy: 0.0019 - val_factorized_top_k/top_5_categorical_accuracy: 0.0086 - val_factorized_top_k/top_10_categorical_accuracy: 0.0123 - val_factorized_top_k/top_50_categorical_accuracy: 0.0305 - val_factorized_top_k/top_100_categorical_accuracy: 0.0459 - val_loss: 67717.0312 - val_regularization_loss: 0.0000e+00 - val_total_loss: 67717.0312\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 24s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0038 - factorized_top_k/top_5_categorical_accuracy: 0.0176 - factorized_top_k/top_10_categorical_accuracy: 0.0261 - factorized_top_k/top_50_categorical_accuracy: 0.0685 - factorized_top_k/top_100_categorical_accuracy: 0.1012 - loss: 262771.0104 - regularization_loss: 0.0000e+00 - total_loss: 262771.0104 - val_factorized_top_k/top_1_categorical_accuracy: 0.0014 - val_factorized_top_k/top_5_categorical_accuracy: 0.0094 - val_factorized_top_k/top_10_categorical_accuracy: 0.0140 - val_factorized_top_k/top_50_categorical_accuracy: 0.0430 - val_factorized_top_k/top_100_categorical_accuracy: 0.0697 - val_loss: 67627.4453 - val_regularization_loss: 0.0000e+00 - val_total_loss: 67627.4453\n"
          ]
        }
      ],
      "source": [
        "#Fit complex model 2\n",
        "start = time.time()\n",
        "model.fit(cached_train, epochs = 10, validation_data = cached_valid)\n",
        "end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grqGn8k-fQR9",
        "outputId": "bf9be634-f783-4535-d5ef-5a14639929d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "247.45911073684692\n"
          ]
        }
      ],
      "source": [
        "#Complex model 2 run time\n",
        "print(end-start)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "H&M_recommender",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}